# 机器学习任务攻略

### Optimization Issue

1. 训练一个浅层次容易optimize的$Model$观察他在训练集上Loss情况
2. 比深层次$Model$和浅层次$Model$的Loss，如果深层次$Model$的Loss更高，则说明产生了Optimization Issue。



### Overfitting

- 在训练集的Loss小而在测试集上的Loss大

**An extreme example**

Training data：${(x^1,y ̂^1 ),(x^2,y ̂^2 ),…,(x^N,y ̂^N )}$

Model：
$$
f\left( x\right) =\begin{cases}\widehat{Y}^{i}  \qquad\qquad \exists x^{i}=x\\  \\  random  \qquad others\end{cases}
$$
可以看到该$Model$在训练集上的Loss为0，但是在测试集上会有很大的Loss

**解决方法：**

1. 增加训练资料
   - 数据增强
2. 对$Model$进行限制
   - 较少的参数
   - 一些参数进行共用
3. 较少的feature
4. Early stopping
5. 正则化
6. Dropout

 



### Overfitting & Optimization Issue

首先观察$Moedel$在测试集上的训练结果如更深层的$Model$的效果差，则观察$Model$在训练集上的效果，如果更深层的$Model$的效果好则可以判断为overfitting，否则则是Optimization issue。

![image-20211030093855625](C:\Users\stydwn\AppData\Roaming\Typora\typora-user-images\image-20211030093855625.png)

### 选择Model

当有N个$Model$怎样选择一个比较好的$Model$作为最终的Model?

解决方案：将数据集分为 Training Set 和 Validation Set。在Training Set 上训练$Model$，在Validation Set 选出Loss最小的$Model$。

优化方案：K折交叉验证：将数据集分为K份，其中n份为Training Set，（k-n）份为Validation Set。在这k份上将所有的 n 与 （k-n）的情况都遍历到，在每一种情况中算出$Model$的Loss，最后将上述每种情况的Loss累加算出均值选出Loss最小的$Model$。

![image-20211030102248361](C:\Users\stydwn\AppData\Roaming\Typora\typora-user-images\image-20211030102248361.png)

### Optimization Tree

![image-20211030103036298](C:\Users\stydwn\AppData\Roaming\Typora\typora-user-images\image-20211030103036298.png)